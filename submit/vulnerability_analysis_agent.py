"""
AI-Powered Vulnerability Detection and Analysis Agent for Neo4j Dependency Graphs

This module provides comprehensive vulnerability analysis capabilities including:
- Integration with multiple vulnerability databases (CVE, GitHub Security Advisories, Snyk)
- AI-powered graph traversal agents for smart dependency analysis
- Intelligent remediation recommendations with compatibility analysis
- Comprehensive vulnerability reports with impact assessment

The system leverages the existing Neo4j dependency graph to provide context-aware
vulnerability analysis and generates actionable remediation strategies.

Required packages:
pip install requests aiohttp langchain-openai python-semver packaging vulnerabilities
"""

import os
import re
import json
import asyncio
import aiohttp
import requests
import hashlib
import time
import random
from typing import List, Dict, Set, Optional, Tuple, Any, Union
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
import semver
from packaging import version
import traceback

# LangChain imports for AI agents
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.messages import HumanMessage, SystemMessage

# Import our dependency graph builder
from dependency_graph_builder import DependencyGraphBuilder

# Environment setup
from dotenv import load_dotenv
load_dotenv()


class VulnerabilitySeverity(Enum):
    """Vulnerability severity levels"""
    CRITICAL = "critical"
    HIGH = "high" 
    MEDIUM = "medium"
    LOW = "low"
    INFO = "info"


class RemediationType(Enum):
    """Types of remediation strategies"""
    VERSION_UPDATE = "version_update"
    PACKAGE_REPLACEMENT = "package_replacement"
    DEPENDENCY_REMOVAL = "dependency_removal"
    CONFIGURATION_CHANGE = "configuration_change"
    CODE_MODIFICATION = "code_modification"


@dataclass
class VulnerabilityData:
    """Represents a vulnerability from external databases"""
    cve_id: Optional[str]
    ghsa_id: Optional[str]
    title: str
    description: str
    severity: VulnerabilitySeverity
    cvss_score: Optional[float]
    affected_packages: List[str]
    affected_versions: List[str]
    fixed_versions: List[str]
    published_date: datetime
    source_db: str  # 'cve', 'github', 'snyk', etc.
    references: List[str] = field(default_factory=list)
    cwe_ids: List[str] = field(default_factory=list)


@dataclass
class AffectedComponent:
    """Represents a component affected by a vulnerability"""
    package_name: str
    current_version: str
    vulnerable_versions: List[str]
    file_paths: List[str]
    dependency_depth: int
    is_direct_dependency: bool
    impact_score: float


@dataclass
class RemediationOption:
    """Represents a remediation strategy"""
    type: RemediationType
    description: str
    target_package: str
    recommended_version: Optional[str]
    alternative_package: Optional[str]
    confidence_score: float
    compatibility_risk: str  # 'low', 'medium', 'high'
    steps: List[str]
    rollback_procedure: List[str]
    test_recommendations: List[str]
    estimated_effort: str  # 'low', 'medium', 'high'


@dataclass
class VulnerabilityReport:
    """Comprehensive vulnerability analysis report"""
    vulnerability: VulnerabilityData
    affected_components: List[AffectedComponent]
    impact_analysis: Dict[str, Any]
    remediation_options: List[RemediationOption]
    recommended_action: RemediationOption
    risk_assessment: Dict[str, Any]
    affected_repositories: List[str]
    dependency_chains: List[List[str]]
    ai_analysis: str
    generated_at: datetime


class VulnerabilityDatabase:
    """Interface for vulnerability database integrations"""
    
    def __init__(self):
        self.session = requests.Session()
        self.cache = {}
        self.cache_expiry = timedelta(hours=6)
        
        # Rate limiting configuration
        self.rate_limits = {
            'snyk': {
                'requests_per_minute': 50,  # Snyk free tier typically allows 50 req/min
                'requests_per_hour': 1000,
                'min_delay': 1.2,  # Minimum seconds between requests
                'max_retries': 3,
                'backoff_factor': 2.0
            },
            'github': {
                'requests_per_minute': 60,  # GitHub API rate limit
                'requests_per_hour': 5000,
                'min_delay': 1.0,
                'max_retries': 3,
                'backoff_factor': 2.0
            },
            'cve': {
                'requests_per_minute': 30,  # Conservative for NVD
                'requests_per_hour': 1000,
                'min_delay': 2.0,
                'max_retries': 3,
                'backoff_factor': 2.0
            }
        }
        
        # Track request timestamps for rate limiting
        self.request_history = {
            'snyk': [],
            'github': [],
            'cve': []
        }
    
    def configure_rate_limits(self, api_name: str, **kwargs):
        """
        Configure rate limits for a specific API
        
        Args:
            api_name: Name of the API ('snyk', 'github', 'cve')
            **kwargs: Rate limit parameters to update:
                - requests_per_minute: Maximum requests per minute
                - requests_per_hour: Maximum requests per hour  
                - min_delay: Minimum seconds between requests
                - max_retries: Maximum retry attempts
                - backoff_factor: Exponential backoff multiplier
        """
        if api_name in self.rate_limits:
            self.rate_limits[api_name].update(kwargs)
            print(f"‚úÖ Updated rate limits for {api_name}: {kwargs}")
        else:
            print(f"‚ö†Ô∏è  Unknown API name: {api_name}")
    
    def get_rate_limit_status(self, api_name: str) -> Dict[str, Any]:
        """Get current rate limit status for an API"""
        if api_name not in self.rate_limits:
            return {"error": f"Unknown API: {api_name}"}
        
        self._clean_request_history(api_name)
        
        now = time.time()
        minute_ago = now - 60
        hour_ago = now - 3600
        
        recent_requests = self.request_history[api_name]
        requests_last_minute = sum(1 for ts in recent_requests if ts > minute_ago)
        requests_last_hour = sum(1 for ts in recent_requests if ts > hour_ago)
        
        config = self.rate_limits[api_name]
        
        return {
            "api": api_name,
            "requests_last_minute": requests_last_minute,
            "requests_last_hour": requests_last_hour,
            "limit_per_minute": config['requests_per_minute'],
            "limit_per_hour": config['requests_per_hour'],
            "can_make_request": self._check_rate_limit(api_name),
            "next_available": self._calculate_delay(api_name),
            "total_requests_tracked": len(recent_requests)
        }
    
    def _clean_request_history(self, api_name: str):
        """Remove old request timestamps beyond the rate limit window"""
        now = time.time()
        minute_ago = now - 60
        hour_ago = now - 3600
        
        # Keep only requests from the last hour
        self.request_history[api_name] = [
            timestamp for timestamp in self.request_history[api_name] 
            if timestamp > hour_ago
        ]
    
    def _check_rate_limit(self, api_name: str) -> bool:
        """Check if we can make a request without exceeding rate limits"""
        self._clean_request_history(api_name)
        
        now = time.time()
        minute_ago = now - 60
        hour_ago = now - 3600
        
        config = self.rate_limits[api_name]
        recent_requests = self.request_history[api_name]
        
        # Count requests in the last minute and hour
        requests_last_minute = sum(1 for ts in recent_requests if ts > minute_ago)
        requests_last_hour = sum(1 for ts in recent_requests if ts > hour_ago)
        
        # Check if we would exceed limits
        if requests_last_minute >= config['requests_per_minute']:
            return False
        if requests_last_hour >= config['requests_per_hour']:
            return False
        
        return True
    
    def _calculate_delay(self, api_name: str) -> float:
        """Calculate how long to wait before next request"""
        config = self.rate_limits[api_name]
        
        if not self.request_history[api_name]:
            return config['min_delay']
        
        last_request = max(self.request_history[api_name])
        time_since_last = time.time() - last_request
        
        if time_since_last < config['min_delay']:
            return config['min_delay'] - time_since_last
        
        return 0
    
    async def _wait_for_rate_limit(self, api_name: str):
        """Wait if necessary to respect rate limits"""
        # Wait for minimum delay
        delay = self._calculate_delay(api_name)
        if delay > 0:
            print(f"‚è±Ô∏è  Rate limiting: waiting {delay:.1f}s for {api_name}")
            await asyncio.sleep(delay)
        
        # If still over limit, wait until we can proceed
        while not self._check_rate_limit(api_name):
            wait_time = 10 + random.uniform(0, 5)  # Wait 10-15 seconds
            print(f"‚è±Ô∏è  Rate limit reached for {api_name}, waiting {wait_time:.1f}s")
            await asyncio.sleep(wait_time)
    
    async def _make_request_with_retry(self, api_name: str, request_func, *args, **kwargs):
        """Make a request with rate limiting and retry logic"""
        config = self.rate_limits[api_name]
        
        for attempt in range(config['max_retries'] + 1):
            try:
                # Wait for rate limit
                await self._wait_for_rate_limit(api_name)
                
                # Record the request timestamp
                self.request_history[api_name].append(time.time())
                
                # Make the request
                if asyncio.iscoroutinefunction(request_func):
                    response = await request_func(*args, **kwargs)
                else:
                    response = request_func(*args, **kwargs)
                
                # Handle rate limit response
                if hasattr(response, 'status_code') and response.status_code == 429:
                    # Remove the failed request from history
                    if self.request_history[api_name]:
                        self.request_history[api_name].pop()
                    
                    if attempt < config['max_retries']:
                        # Exponential backoff starting with reasonable base time
                        base_wait = 5  # Start with 5 seconds for 429 errors
                        wait_time = base_wait * (config['backoff_factor'] ** attempt)
                        jitter = random.uniform(0, wait_time * 0.1)  # 10% jitter
                        total_wait = wait_time + jitter
                        
                        print(f"üîÑ Rate limited by {api_name} (429), retrying in {total_wait:.1f}s (attempt {attempt + 1}/{config['max_retries'] + 1})")
                        await asyncio.sleep(total_wait)
                        continue
                    else:
                        print(f"‚ùå Max retries exceeded for {api_name} due to rate limiting")
                        return None
                
                return response
                
            except Exception as e:
                if attempt < config['max_retries']:
                    wait_time = (config['backoff_factor'] ** attempt) * 5
                    print(f"‚ö†Ô∏è  Request failed for {api_name}, retrying in {wait_time:.1f}s: {e}")
                    await asyncio.sleep(wait_time)
                    continue
                else:
                    print(f"‚ùå Max retries exceeded for {api_name}: {e}")
                    raise
        
        return None
    
    async def query_cve_database(self, package_name: str, version: str = None) -> List[VulnerabilityData]:
        """Query CVE database for package vulnerabilities with rate limiting"""
        try:
            # Using National Vulnerability Database API
            url = "https://services.nvd.nist.gov/rest/json/cves/2.0"
            params = {
                "keywordSearch": package_name,
                "resultsPerPage": 50
            }
            
            cache_key = f"cve_{package_name}_{version or 'all'}"
            if self._is_cached_valid(cache_key):
                return self.cache[cache_key]
            
            # Define the request function for rate limiting
            def make_cve_request():
                response = self.session.get(url, params=params)
                response.raise_for_status()
                return response
            
            # Make request with rate limiting and retry logic
            response = await self._make_request_with_retry('cve', make_cve_request)
            
            if response is None:
                print("‚ùå Failed to get response from CVE database after retries")
                return []
            
            data = response.json()
            vulnerabilities = []
            
            for cve in data.get('vulnerabilities', []):
                cve_data = cve.get('cve', {})
                vuln = self._parse_cve_data(cve_data, package_name)
                if vuln:
                    vulnerabilities.append(vuln)
            
            self.cache[cache_key] = vulnerabilities
            return vulnerabilities
            
        except Exception as e:
            print(f"‚ùå Error querying CVE database: {e}")
            return []
    
    async def query_github_advisories(self, package_name: str) -> List[VulnerabilityData]:
        """Query GitHub Security Advisories"""
        try:
            # GitHub GraphQL API for security advisories
            github_token = os.getenv('GITHUB_PAT')
            if not github_token:
                print("‚ö†Ô∏è  GitHub token not available, skipping GitHub advisories")
                return []
            
            cache_key = f"github_{package_name}"
            if self._is_cached_valid(cache_key):
                return self.cache[cache_key]
            
            query = """
            query($package: String!) {
              securityAdvisories(first: 50, orderBy: {field: PUBLISHED_AT, direction: DESC}) {
                nodes {
                  ghsaId
                  summary
                  description
                  severity
                  publishedAt
                  vulnerabilities(first: 10) {
                    nodes {
                      package {
                        name
                      }
                      vulnerableVersionRange
                      firstPatchedVersion {
                        identifier
                      }
                    }
                  }
                  references {
                    url
                  }
                  cwes(first: 5) {
                    nodes {
                      cweId
                    }
                  }
                }
              }
            }
            """
            
            headers = {
                'Authorization': f'Bearer {github_token}',
                'Content-Type': 'application/json'
            }
            
            # Define the request function for rate limiting
            def make_github_request():
                return self.session.post(
                    'https://api.github.com/graphql',
                    headers=headers,
                    json={'query': query, 'variables': {'package': package_name}}
                )
            
            # Make request with rate limiting and retry logic
            response = await self._make_request_with_retry('github', make_github_request)
            
            if response is None:
                print("‚ùå Failed to get response from GitHub after retries")
                return []
            
            if response.status_code == 200:
                data = response.json()
                vulnerabilities = self._parse_github_advisories(data, package_name)
                self.cache[cache_key] = vulnerabilities
                return vulnerabilities
            else:
                print(f"‚ö†Ô∏è  GitHub API error: {response.status_code}")
                if hasattr(response, 'text'):
                    print(f"    Response: {response.text[:200]}")
                return []
                
        except Exception as e:
            print(f"‚ùå Error querying GitHub advisories: {e}")
            return []
    
    async def query_snyk_database(self, package_name: str, ecosystem: str = "npm") -> List[VulnerabilityData]:
        """Query Snyk vulnerability database with rate limiting"""
        try:
            # Snyk API (requires API key)
            snyk_token = os.getenv('SNYK_TOKEN')
            if not snyk_token:
                print("‚ö†Ô∏è  Snyk token not available, skipping Snyk database")
                return []
            
            cache_key = f"snyk_{ecosystem}_{package_name}"
            if self._is_cached_valid(cache_key):
                return self.cache[cache_key]
            
            url = f"https://api.snyk.io/v1/vuln/{ecosystem}/{package_name}"
            headers = {
                'Authorization': f'token {snyk_token}',
                'Content-Type': 'application/json'
            }
            
            # Define the request function for rate limiting
            def make_snyk_request():
                return self.session.get(url, headers=headers)
            
            # Make request with rate limiting and retry logic
            response = await self._make_request_with_retry('snyk', make_snyk_request)
            
            if response is None:
                print("‚ùå Failed to get response from Snyk after retries")
                return []
            
            if response.status_code == 200:
                data = response.json()
                vulnerabilities = self._parse_snyk_data(data, package_name)
                self.cache[cache_key] = vulnerabilities
                return vulnerabilities
            elif response.status_code == 404:
                # Package not found in Snyk database - this is normal
                print(f"üìù Package {package_name} not found in Snyk database")
                return []
            elif response.status_code == 429:
                # This should be handled by the retry logic, but just in case
                print(f"‚ö†Ô∏è  Snyk rate limit exceeded, but retry logic should have handled this")
                return []
            else:
                print(f"‚ö†Ô∏è  Snyk API error: {response.status_code}")
                if hasattr(response, 'text'):
                    print(f"    Response: {response.text[:200]}")
                return []
                
        except Exception as e:
            print(f"‚ùå Error querying Snyk database: {e}")
            return []
    
    def _is_cached_valid(self, cache_key: str) -> bool:
        """Check if cached data is still valid"""
        if cache_key not in self.cache:
            return False
        # For simplicity, assuming cache metadata is stored separately
        return False  # Always refresh for demo
    
    def _parse_cve_data(self, cve_data: Dict, package_name: str) -> Optional[VulnerabilityData]:
        """Parse CVE JSON data into VulnerabilityData"""
        try:
            cve_id = cve_data.get('id', '')
            
            # Extract description
            descriptions = cve_data.get('descriptions', [])
            description = ""
            for desc in descriptions:
                if desc.get('lang') == 'en':
                    description = desc.get('value', '')
                    break
            
            # Extract CVSS score and severity
            metrics = cve_data.get('metrics', {})
            cvss_score = None
            severity = VulnerabilitySeverity.MEDIUM
            
            if 'cvssMetricV31' in metrics:
                cvss_data = metrics['cvssMetricV31'][0]['cvssData']
                cvss_score = cvss_data.get('baseScore')
                severity_str = cvss_data.get('baseSeverity', '').lower()
                severity = VulnerabilitySeverity(severity_str) if severity_str in [s.value for s in VulnerabilitySeverity] else VulnerabilitySeverity.MEDIUM
            
            # Extract references
            references = []
            for ref in cve_data.get('references', []):
                references.append(ref.get('url', ''))
            
            # Extract CWE IDs
            cwe_ids = []
            for weakness in cve_data.get('weaknesses', []):
                for desc in weakness.get('description', []):
                    if desc.get('lang') == 'en':
                        cwe_ids.append(desc.get('value', ''))
            
            # Extract publish date
            published_date = datetime.now()
            if 'published' in cve_data:
                published_date = datetime.fromisoformat(cve_data['published'].replace('Z', '+00:00'))
            
            return VulnerabilityData(
                cve_id=cve_id,
                ghsa_id=None,
                title=f"CVE {cve_id}",
                description=description,
                severity=severity,
                cvss_score=cvss_score,
                affected_packages=[package_name],
                affected_versions=["*"],  # Would need more parsing for specific versions
                fixed_versions=[],
                published_date=published_date,
                source_db="cve",
                references=references,
                cwe_ids=cwe_ids
            )
        except Exception as e:
            print(f"‚ö†Ô∏è  Error parsing CVE data: {e}")
            return None
    
    def _parse_github_advisories(self, data: Dict, package_name: str) -> List[VulnerabilityData]:
        """Parse GitHub Security Advisories data"""
        vulnerabilities = []
        try:
            advisories = data.get('data', {}).get('securityAdvisories', {}).get('nodes', [])
            
            for advisory in advisories:
                # Check if this advisory affects our package
                affects_package = False
                affected_versions = []
                fixed_versions = []
                
                for vuln in advisory.get('vulnerabilities', {}).get('nodes', []):
                    pkg = vuln.get('package', {}).get('name', '')
                    if package_name.lower() in pkg.lower() or pkg.lower() in package_name.lower():
                        affects_package = True
                        affected_versions.append(vuln.get('vulnerableVersionRange', ''))
                        if vuln.get('firstPatchedVersion'):
                            fixed_versions.append(vuln['firstPatchedVersion']['identifier'])
                
                if affects_package:
                    severity_str = advisory.get('severity', 'MEDIUM').lower()
                    severity = VulnerabilitySeverity(severity_str) if severity_str in [s.value for s in VulnerabilitySeverity] else VulnerabilitySeverity.MEDIUM
                    
                    references = [ref['url'] for ref in advisory.get('references', [])]
                    cwe_ids = [cwe['cweId'] for cwe in advisory.get('cwes', {}).get('nodes', [])]
                    
                    published_date = datetime.now()
                    if advisory.get('publishedAt'):
                        published_date = datetime.fromisoformat(advisory['publishedAt'].replace('Z', '+00:00'))
                    
                    vuln = VulnerabilityData(
                        cve_id=None,
                        ghsa_id=advisory.get('ghsaId'),
                        title=advisory.get('summary', ''),
                        description=advisory.get('description', ''),
                        severity=severity,
                        cvss_score=None,
                        affected_packages=[package_name],
                        affected_versions=affected_versions,
                        fixed_versions=fixed_versions,
                        published_date=published_date,
                        source_db="github",
                        references=references,
                        cwe_ids=cwe_ids
                    )
                    vulnerabilities.append(vuln)
        
        except Exception as e:
            print(f"‚ö†Ô∏è  Error parsing GitHub advisories: {e}")
        
        return vulnerabilities
    
    def _parse_snyk_data(self, data: Dict, package_name: str) -> List[VulnerabilityData]:
        """Parse Snyk vulnerability data"""
        vulnerabilities = []
        try:
            issues = data.get('issues', {})
            
            for vuln_id, vuln_data in issues.items():
                severity_str = vuln_data.get('severity', 'medium').lower()
                severity = VulnerabilitySeverity(severity_str) if severity_str in [s.value for s in VulnerabilitySeverity] else VulnerabilitySeverity.MEDIUM
                
                vuln = VulnerabilityData(
                    cve_id=vuln_data.get('identifiers', {}).get('CVE', [None])[0],
                    ghsa_id=None,
                    title=vuln_data.get('title', ''),
                    description=vuln_data.get('description', ''),
                    severity=severity,
                    cvss_score=vuln_data.get('cvssScore'),
                    affected_packages=[package_name],
                    affected_versions=vuln_data.get('semver', {}).get('vulnerable', []),
                    fixed_versions=[],
                    published_date=datetime.now(),
                    source_db="snyk",
                    references=vuln_data.get('references', []),
                    cwe_ids=vuln_data.get('identifiers', {}).get('CWE', [])
                )
                vulnerabilities.append(vuln)
        
        except Exception as e:
            print(f"‚ö†Ô∏è  Error parsing Snyk data: {e}")
        
        return vulnerabilities


class AIGraphTraversalAgent:
    """AI-powered agent for intelligent graph traversal and analysis"""
    
    def __init__(self, model_name: str = "gpt-4.1-mini"):
        """Initialize the AI agent"""
        self.llm = ChatOpenAI(temperature=0.1, model=model_name)
        self.analysis_cache = {}
    
    async def analyze_vulnerability_impact(self, 
                                         vulnerability: VulnerabilityData,
                                         affected_components: List[AffectedComponent],
                                         dependency_graph: DependencyGraphBuilder) -> Dict[str, Any]:
        """AI-powered analysis of vulnerability impact"""
        
        # Gather context from the dependency graph
        graph_context = await self._gather_graph_context(affected_components, dependency_graph)
        
        # Create analysis prompt
        analysis_prompt = PromptTemplate(
            input_variables=["vulnerability_data", "affected_components", "graph_context"],
            template="""You are a cybersecurity expert analyzing a vulnerability in a software dependency graph.

VULNERABILITY DETAILS:
{vulnerability_data}

AFFECTED COMPONENTS:
{affected_components}

DEPENDENCY GRAPH CONTEXT:
{graph_context}

Provide a comprehensive impact analysis including:

1. SEVERITY ASSESSMENT:
   - Real-world exploitability (not just theoretical)
   - Likelihood of successful attack
   - Potential business impact

2. RISK FACTORS:
   - Attack surface exposure
   - Data sensitivity at risk
   - System criticality affected

3. PROPAGATION ANALYSIS:
   - How the vulnerability could spread through dependencies
   - Critical paths and chokepoints
   - Cascade failure potential

4. URGENCY RECOMMENDATION:
   - Timeline for remediation (immediate, within 24h, within week, etc.)
   - Risk tolerance considerations
   - Resource allocation priority

5. CONTEXTUAL INSIGHTS:
   - Package usage patterns that affect risk
   - Code context that may mitigate or amplify risk
   - Environmental factors

Provide your analysis in JSON format with clear reasoning for each assessment."""
        )
        
        # Prepare data for the prompt
        vuln_summary = f"""
Title: {vulnerability.title}
Severity: {vulnerability.severity.value}
CVSS Score: {vulnerability.cvss_score or 'N/A'}
Description: {vulnerability.description[:500]}...
Affected Packages: {', '.join(vulnerability.affected_packages)}
Source: {vulnerability.source_db}
"""
        
        components_summary = "\n".join([
            f"- {comp.package_name} v{comp.current_version} (depth: {comp.dependency_depth}, files: {len(comp.file_paths)})"
            for comp in affected_components[:10]  # Limit for prompt length
        ])
        
        # Generate analysis
        try:
            formatted_prompt = analysis_prompt.format(
                vulnerability_data=vuln_summary,
                affected_components=components_summary,
                graph_context=json.dumps(graph_context, indent=2)
            )
            
            response = await self.llm.ainvoke([HumanMessage(content=formatted_prompt)])
            
            # Parse the response
            analysis_text = response.content
            
            # Try to extract JSON if provided, otherwise use text analysis
            try:
                if "```json" in analysis_text:
                    json_part = analysis_text.split("```json")[1].split("```")[0]
                    analysis_data = json.loads(json_part)
                else:
                    # Fallback to structured text analysis
                    analysis_data = {
                        "severity_assessment": self._extract_section(analysis_text, "SEVERITY ASSESSMENT"),
                        "risk_factors": self._extract_section(analysis_text, "RISK FACTORS"),
                        "propagation_analysis": self._extract_section(analysis_text, "PROPAGATION ANALYSIS"),
                        "urgency_recommendation": self._extract_section(analysis_text, "URGENCY RECOMMENDATION"),
                        "contextual_insights": self._extract_section(analysis_text, "CONTEXTUAL INSIGHTS")
                    }
            except json.JSONDecodeError:
                analysis_data = {"raw_analysis": analysis_text}
            
            # Add computed metrics
            analysis_data.update({
                "ai_risk_score": self._calculate_ai_risk_score(vulnerability, affected_components, analysis_text),
                "remediation_urgency": self._determine_urgency(vulnerability, analysis_text),
                "impact_radius": len(affected_components),
                "critical_path_count": len([c for c in affected_components if c.dependency_depth <= 2])
            })
            
            return analysis_data
            
        except Exception as e:
            print(f"‚ùå Error in AI impact analysis: {e}")
            return {
                "error": str(e),
                "fallback_analysis": self._generate_fallback_analysis(vulnerability, affected_components)
            }
    
    async def generate_remediation_strategies(self,
                                            vulnerability: VulnerabilityData,
                                            affected_components: List[AffectedComponent],
                                            dependency_graph: DependencyGraphBuilder) -> List[RemediationOption]:
        """Generate intelligent remediation strategies using AI"""
        
        remediation_prompt = PromptTemplate(
            input_variables=["vulnerability_data", "affected_components", "dependency_context"],
            template="""You are a software engineering expert specializing in dependency management and security remediation.

VULNERABILITY TO REMEDIATE:
{vulnerability_data}

AFFECTED COMPONENTS:
{affected_components}

DEPENDENCY CONTEXT:
{dependency_context}

Generate 3-5 ranked remediation strategies. For each strategy, provide:

1. STRATEGY TYPE: (version_update, package_replacement, dependency_removal, configuration_change, code_modification)
2. DESCRIPTION: Clear explanation of the approach
3. TARGET_PACKAGE: Primary package to modify
4. RECOMMENDED_VERSION: Specific version if applicable
5. ALTERNATIVE_PACKAGE: Alternative package name if replacing
6. CONFIDENCE_SCORE: 0.0-1.0 based on likelihood of success
7. COMPATIBILITY_RISK: low/medium/high assessment
8. STEPS: Detailed implementation steps
9. ROLLBACK_PROCEDURE: How to undo if issues arise
10. TEST_RECOMMENDATIONS: How to verify the fix works
11. ESTIMATED_EFFORT: low/medium/high time investment

Consider:
- Breaking changes in version updates
- Compatibility with other dependencies
- Code modifications required
- Testing complexity
- Risk of introducing new issues

Provide response in JSON array format with each strategy as an object."""
        )
        
        # Gather dependency context
        dependency_context = await self._gather_dependency_context(affected_components, dependency_graph)
        
        # Prepare data
        vuln_data = f"{vulnerability.title}\nSeverity: {vulnerability.severity.value}\nAffected: {', '.join(vulnerability.affected_packages)}"
        components_data = "\n".join([f"{c.package_name} v{c.current_version}" for c in affected_components])
        
        try:
            formatted_prompt = remediation_prompt.format(
                vulnerability_data=vuln_data,
                affected_components=components_data,
                dependency_context=json.dumps(dependency_context, indent=2)
            )
            
            response = await self.llm.ainvoke([HumanMessage(content=formatted_prompt)])
            
            # Parse response to RemediationOption objects
            response_text = response.content
            strategies = self._parse_remediation_strategies(response_text, vulnerability, affected_components)
            
            return strategies
            
        except Exception as e:
            print(f"‚ùå Error generating remediation strategies: {e}")
            return self._generate_fallback_strategies(vulnerability, affected_components)
    
    async def _gather_graph_context(self, affected_components: List[AffectedComponent], dependency_graph: DependencyGraphBuilder) -> Dict[str, Any]:
        """Gather relevant context from the dependency graph"""
        context = {
            "total_affected_files": sum(len(comp.file_paths) for comp in affected_components),
            "dependency_depths": [comp.dependency_depth for comp in affected_components],
            "direct_dependencies": [comp.package_name for comp in affected_components if comp.is_direct_dependency],
            "indirect_dependencies": [comp.package_name for comp in affected_components if not comp.is_direct_dependency],
        }
        
        # Get repository statistics
        try:
            with dependency_graph.driver.session() as session:
                # Get affected repositories
                repo_query = """
                MATCH (f:File)-[:DEPENDS_ON]->(p:Package)
                WHERE p.name IN $packages
                RETURN DISTINCT f.repo_name as repo
                """
                packages = [comp.package_name for comp in affected_components]
                result = session.run(repo_query, packages=packages)
                context["affected_repositories"] = [record["repo"] for record in result]
                
                # Get dependency chain lengths
                chain_query = """
                MATCH path = (f:File)-[:DEPENDS_ON*1..5]->(p:Package)
                WHERE p.name IN $packages
                RETURN length(path) as chain_length, count(*) as count
                """
                result = session.run(chain_query, packages=packages)
                context["dependency_chain_stats"] = {record["chain_length"]: record["count"] for record in result}
        
        except Exception as e:
            print(f"‚ö†Ô∏è  Error gathering graph context: {e}")
        
        return context
    
    async def _gather_dependency_context(self, affected_components: List[AffectedComponent], dependency_graph: DependencyGraphBuilder) -> Dict[str, Any]:
        """Gather dependency relationship context for remediation planning"""
        context = {}
        
        try:
            with dependency_graph.driver.session() as session:
                for component in affected_components:
                    # Get dependencies of this package
                    deps_query = """
                    MATCH (f:File)-[:DEPENDS_ON]->(p:Package {name: $package})
                    RETURN f.file_type as file_type, count(f) as usage_count
                    """
                    result = session.run(deps_query, package=component.package_name)
                    
                    context[component.package_name] = {
                        "usage_by_file_type": {record["file_type"]: record["usage_count"] for record in result},
                        "current_version": component.current_version,
                        "is_direct": component.is_direct_dependency
                    }
        
        except Exception as e:
            print(f"‚ö†Ô∏è  Error gathering dependency context: {e}")
        
        return context
    
    def _extract_section(self, text: str, section_name: str) -> str:
        """Extract a specific section from analysis text"""
        pattern = rf"{section_name}:(.*?)(?=\n\d+\.|$)"
        match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)
        return match.group(1).strip() if match else ""
    
    def _calculate_ai_risk_score(self, vulnerability: VulnerabilityData, components: List[AffectedComponent], analysis: str) -> float:
        """Calculate an AI-informed risk score"""
        base_score = 0.5
        
        # Severity factor
        severity_weights = {
            VulnerabilitySeverity.CRITICAL: 1.0,
            VulnerabilitySeverity.HIGH: 0.8,
            VulnerabilitySeverity.MEDIUM: 0.6,
            VulnerabilitySeverity.LOW: 0.4,
            VulnerabilitySeverity.INFO: 0.2
        }
        base_score *= severity_weights.get(vulnerability.severity, 0.5)
        
        # Component impact factor
        direct_deps = sum(1 for c in components if c.is_direct_dependency)
        impact_factor = min(1.0, (direct_deps * 0.3 + len(components) * 0.1))
        
        # AI analysis sentiment (basic keyword analysis)
        urgent_keywords = ["immediate", "critical", "exploit", "active", "widespread"]
        mitigating_keywords = ["theoretical", "limited", "requires", "unlikely"]
        
        urgency_boost = sum(0.1 for keyword in urgent_keywords if keyword.lower() in analysis.lower())
        mitigation_reduction = sum(0.1 for keyword in mitigating_keywords if keyword.lower() in analysis.lower())
        
        final_score = min(1.0, base_score + impact_factor + urgency_boost - mitigation_reduction)
        return round(final_score, 2)
    
    def _determine_urgency(self, vulnerability: VulnerabilityData, analysis: str) -> str:
        """Determine remediation urgency from AI analysis"""
        if "immediate" in analysis.lower() or vulnerability.severity == VulnerabilitySeverity.CRITICAL:
            return "immediate"
        elif "24" in analysis or vulnerability.severity == VulnerabilitySeverity.HIGH:
            return "within_24h"
        elif "week" in analysis or vulnerability.severity == VulnerabilitySeverity.MEDIUM:
            return "within_week"
        else:
            return "normal_cycle"
    
    def _parse_remediation_strategies(self, response_text: str, vulnerability: VulnerabilityData, components: List[AffectedComponent]) -> List[RemediationOption]:
        """Parse AI response into RemediationOption objects"""
        strategies = []
        
        try:
            # Try to extract JSON from response
            if "```json" in response_text:
                json_part = response_text.split("```json")[1].split("```")[0]
                strategies_data = json.loads(json_part)
            else:
                # Fallback parsing
                strategies_data = self._fallback_parse_strategies(response_text)
            
            for strategy_data in strategies_data:
                strategy = RemediationOption(
                    type=RemediationType(strategy_data.get("strategy_type", "version_update")),
                    description=strategy_data.get("description", ""),
                    target_package=strategy_data.get("target_package", components[0].package_name if components else ""),
                    recommended_version=strategy_data.get("recommended_version"),
                    alternative_package=strategy_data.get("alternative_package"),
                    confidence_score=float(strategy_data.get("confidence_score", 0.5)),
                    compatibility_risk=strategy_data.get("compatibility_risk", "medium"),
                    steps=strategy_data.get("steps", []),
                    rollback_procedure=strategy_data.get("rollback_procedure", []),
                    test_recommendations=strategy_data.get("test_recommendations", []),
                    estimated_effort=strategy_data.get("estimated_effort", "medium")
                )
                strategies.append(strategy)
        
        except Exception as e:
            print(f"‚ö†Ô∏è  Error parsing remediation strategies: {e}")
            strategies = self._generate_fallback_strategies(vulnerability, components)
        
        return strategies
    
    def _fallback_parse_strategies(self, text: str) -> List[Dict]:
        """Fallback parsing when JSON extraction fails"""
        # Simple text-based parsing
        return [{
            "strategy_type": "version_update",
            "description": "Update to latest secure version",
            "confidence_score": 0.7,
            "compatibility_risk": "medium",
            "steps": ["Check for updates", "Test in development", "Deploy"],
            "rollback_procedure": ["Revert to previous version"],
            "test_recommendations": ["Run full test suite"],
            "estimated_effort": "medium"
        }]
    
    def _generate_fallback_analysis(self, vulnerability: VulnerabilityData, components: List[AffectedComponent]) -> Dict[str, Any]:
        """Generate basic analysis when AI fails"""
        return {
            "severity_assessment": f"Vulnerability rated as {vulnerability.severity.value}",
            "risk_factors": f"Affects {len(components)} components",
            "remediation_urgency": "normal_cycle",
            "ai_risk_score": 0.5
        }
    
    def _generate_fallback_strategies(self, vulnerability: VulnerabilityData, components: List[AffectedComponent]) -> List[RemediationOption]:
        """Generate basic strategies when AI fails"""
        strategies = []
        
        for component in components[:3]:  # Limit to top 3
            strategy = RemediationOption(
                type=RemediationType.VERSION_UPDATE,
                description=f"Update {component.package_name} to latest secure version",
                target_package=component.package_name,
                recommended_version=None,
                alternative_package=None,
                confidence_score=0.7,
                compatibility_risk="medium",
                steps=[
                    f"Check latest version of {component.package_name}",
                    "Update package manager file",
                    "Run tests",
                    "Deploy update"
                ],
                rollback_procedure=[
                    f"Revert {component.package_name} to version {component.current_version}",
                    "Redeploy previous version"
                ],
                test_recommendations=[
                    "Run unit tests",
                    "Run integration tests",
                    "Verify no new vulnerabilities"
                ],
                estimated_effort="medium"
            )
            strategies.append(strategy)
        
        return strategies


class VulnerabilityAnalysisAgent:
    """Main agent orchestrating vulnerability detection and analysis"""
    
    def __init__(self, dependency_graph: DependencyGraphBuilder):
        """Initialize the vulnerability analysis agent"""
        self.dependency_graph = dependency_graph
        self.vuln_db = VulnerabilityDatabase()
        self.ai_agent = AIGraphTraversalAgent()
        self.reports = []
    
    async def analyze_all_repositories(self) -> List[VulnerabilityReport]:
        """Analyze all repositories in the Neo4j graph for vulnerabilities"""
        print("üîç Starting comprehensive vulnerability analysis...")
        
        # Get all packages from the graph
        packages = await self._get_all_packages()
        print(f"üì¶ Found {len(packages)} unique packages to analyze")
        
        all_reports = []
        
        for pkg_idx, package_info in enumerate(packages[:3], 1):
            package_name = package_info["name"]
            repos = package_info["repos"]
            
            print(f"üîç Package {pkg_idx}/{len(packages)}: Analyzing {package_name}")
            
            # Query multiple vulnerability databases
            vulnerabilities = await self._query_all_databases(package_name)
            
            if vulnerabilities:
                print(f"‚ö†Ô∏è  Found {len(vulnerabilities)} vulnerabilities for {package_name}")
                
                for vuln_idx, vulnerability in enumerate(vulnerabilities[:1], 1):
                    # Progress indicator that overwrites the same line
                    print(f"\r   üìä Analyzing vulnerability {vuln_idx}/{len(vulnerabilities)}: {vulnerability.title[:50]}...", end='', flush=True)
                    
                    report = await self._analyze_vulnerability(vulnerability, package_name, repos)
                    if report:
                        all_reports.append(report)
                
                # Clear the progress line and print completion
                print(f"\r   ‚úÖ Completed analysis of {len(vulnerabilities)} vulnerabilities for {package_name}" + " " * 20)
            else:
                print(f"‚úÖ No vulnerabilities found for {package_name}")
        
        self.reports = all_reports
        print(f"üìä Vulnerability analysis complete: {len(all_reports)} issues found")
        
        return all_reports
    
    async def _get_all_packages(self) -> List[Dict[str, Any]]:
        """Get all external packages from the dependency graph"""
        packages = []
        
        try:
            with self.dependency_graph.driver.session() as session:
                query = """
                MATCH (p:Package)
                OPTIONAL MATCH (f:File)-[:DEPENDS_ON]->(p)
                RETURN p.name as name, 
                       collect(DISTINCT f.repo_name) as repos,
                       count(DISTINCT f) as usage_count
                ORDER BY usage_count DESC
                """
                
                result = session.run(query)
                for record in result:
                    packages.append({
                        "name": record["name"],
                        "repos": [repo for repo in record["repos"] if repo],
                        "usage_count": record["usage_count"]
                    })
        
        except Exception as e:
            print(f"‚ùå Error getting packages: {e}")
        
        return packages
    
    async def _query_all_databases(self, package_name: str) -> List[VulnerabilityData]:
        """Query all vulnerability databases for a package"""
        all_vulnerabilities = []
        
        # Query CVE database
        cve_vulns = await self.vuln_db.query_cve_database(package_name)
        all_vulnerabilities.extend(cve_vulns)
        
        # Query GitHub Security Advisories
        github_vulns = await self.vuln_db.query_github_advisories(package_name)
        all_vulnerabilities.extend(github_vulns)
        
        # Query Snyk (determine ecosystem from package name)
        ecosystem = self._determine_ecosystem(package_name)
        snyk_vulns = await self.vuln_db.query_snyk_database(package_name, ecosystem)
        all_vulnerabilities.extend(snyk_vulns)
        
        # Deduplicate by CVE ID or description
        unique_vulns = self._deduplicate_vulnerabilities(all_vulnerabilities)
        
        return unique_vulns
    
    def _determine_ecosystem(self, package_name: str) -> str:
        """Determine package ecosystem (npm, pypi, maven, etc.)"""
        # Simple heuristics - could be improved with more sophisticated detection
        if "@" in package_name or "/" in package_name:
            return "npm"
        elif "-" in package_name and "." not in package_name:
            return "pypi"
        elif "." in package_name and package_name.count(".") >= 2:
            return "maven"
        else:
            return "npm"  # Default fallback
    
    def _deduplicate_vulnerabilities(self, vulnerabilities: List[VulnerabilityData]) -> List[VulnerabilityData]:
        """Remove duplicate vulnerabilities based on CVE ID or content similarity"""
        seen_cves = set()
        seen_descriptions = set()
        unique_vulns = []
        
        for vuln in vulnerabilities:
            # Check CVE ID first
            if vuln.cve_id and vuln.cve_id in seen_cves:
                continue
            
            # Check description similarity (simple hash-based)
            desc_hash = hashlib.md5(vuln.description.encode()).hexdigest()
            if desc_hash in seen_descriptions:
                continue
            
            # Add to unique list
            unique_vulns.append(vuln)
            if vuln.cve_id:
                seen_cves.add(vuln.cve_id)
            seen_descriptions.add(desc_hash)
        
        return unique_vulns
    
    async def _analyze_vulnerability(self, vulnerability: VulnerabilityData, package_name: str, affected_repos: List[str]) -> Optional[VulnerabilityReport]:
        """Perform comprehensive analysis of a single vulnerability"""
        
        # Get affected components from graph
        affected_components = await self._get_affected_components(package_name, affected_repos)
        
        if not affected_components:
            return None
        
        # AI-powered impact analysis
        impact_analysis = await self.ai_agent.analyze_vulnerability_impact(
            vulnerability, affected_components, self.dependency_graph
        )
        
        # Generate remediation strategies
        remediation_options = await self.ai_agent.generate_remediation_strategies(
            vulnerability, affected_components, self.dependency_graph
        )
        
        # Select recommended action
        recommended_action = self._select_recommended_action(remediation_options)
        
        # Generate dependency chains
        dependency_chains = await self._get_dependency_chains(package_name, affected_repos)
        
        # Create comprehensive report
        report = VulnerabilityReport(
            vulnerability=vulnerability,
            affected_components=affected_components,
            impact_analysis=impact_analysis,
            remediation_options=remediation_options,
            recommended_action=recommended_action,
            risk_assessment=self._generate_risk_assessment(vulnerability, affected_components, impact_analysis),
            affected_repositories=affected_repos,
            dependency_chains=dependency_chains,
            ai_analysis=impact_analysis.get("raw_analysis", "AI analysis completed"),
            generated_at=datetime.now()
        )
        
        return report
    
    async def _get_affected_components(self, package_name: str, affected_repos: List[str]) -> List[AffectedComponent]:
        """Get detailed information about affected components"""
        components = []
        
        try:
            with self.dependency_graph.driver.session() as session:
                query = """
                MATCH (f:File)-[d:DEPENDS_ON]->(p:Package {name: $package_name})
                WHERE f.repo_name IN $repos
                WITH f, d, p
                OPTIONAL MATCH path = (f)-[:DEPENDS_ON*1..5]->(p)
                RETURN f.path as file_path,
                       f.repo_name as repo,
                       length(path) as dependency_depth,
                       d.dependency_type as dep_type,
                       collect(f.path) as all_files
                """
                
                result = session.run(query, package_name=package_name, repos=affected_repos)
                
                # Collect all records first to avoid cursor exhaustion
                records = list(result)
                
                if records:
                    file_paths = []
                    dependency_depths = []
                    dep_types = []
                    
                    for record in records:
                        if record["file_path"]:
                            file_paths.append(record["file_path"])
                        if record["dependency_depth"]:
                            dependency_depths.append(record["dependency_depth"])
                        if record["dep_type"]:
                            dep_types.append(record["dep_type"])
                    
                    # Create affected component
                    if file_paths:
                        component = AffectedComponent(
                            package_name=package_name,
                            current_version="unknown",  # Would need version tracking
                            vulnerable_versions=["*"],
                            file_paths=file_paths,
                            dependency_depth=min(dependency_depths) if dependency_depths else 1,
                            is_direct_dependency=any(dep_type == "package" for dep_type in dep_types),
                            impact_score=len(file_paths) * 0.1  # Simple scoring
                        )
                        components.append(component)
        
        except Exception as e:
            print(f"‚ùå Error getting affected components: {e}")
        
        return components
    
    async def _get_dependency_chains(self, package_name: str, affected_repos: List[str]) -> List[List[str]]:
        """Get dependency chains leading to the vulnerable package"""
        chains = []
        
        try:
            with self.dependency_graph.driver.session() as session:
                query = """
                MATCH path = (f:File)-[:DEPENDS_ON*1..5]->(p:Package {name: $package_name})
                WHERE f.repo_name IN $repos
                RETURN [n in nodes(path) | CASE 
                    WHEN 'File' IN labels(n) THEN n.path 
                    WHEN 'Package' IN labels(n) THEN n.name 
                    END] as chain
                LIMIT 20
                """
                
                result = session.run(query, package_name=package_name, repos=affected_repos)
                
                for record in result:
                    chain = [node for node in record["chain"] if node]
                    if len(chain) > 1:
                        chains.append(chain)
        
        except Exception as e:
            print(f"‚ùå Error getting dependency chains: {e}")
        
        return chains
    
    def _select_recommended_action(self, remediation_options: List[RemediationOption]) -> Optional[RemediationOption]:
        """Select the best remediation option based on confidence and risk"""
        if not remediation_options:
            return None
        
        # Sort by confidence score and compatibility risk
        def score_option(option):
            risk_penalty = {"low": 0, "medium": 0.1, "high": 0.3}
            return option.confidence_score - risk_penalty.get(option.compatibility_risk, 0.2)
        
        return max(remediation_options, key=score_option)
    
    def _generate_risk_assessment(self, vulnerability: VulnerabilityData, components: List[AffectedComponent], impact_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """Generate comprehensive risk assessment"""
        
        # Calculate business risk factors
        affected_files = sum(len(comp.file_paths) for comp in components)
        direct_deps = sum(1 for comp in components if comp.is_direct_dependency)
        
        return {
            "overall_risk": impact_analysis.get("ai_risk_score", 0.5),
            "technical_risk": {
                "affected_files_count": affected_files,
                "direct_dependencies": direct_deps,
                "dependency_depth": max((comp.dependency_depth for comp in components), default=1)
            },
            "business_impact": {
                "severity": vulnerability.severity.value,
                "exploitability": impact_analysis.get("severity_assessment", "Unknown"),
                "remediation_urgency": impact_analysis.get("remediation_urgency", "normal_cycle")
            },
            "confidence_metrics": {
                "vulnerability_data_quality": "high" if vulnerability.cve_id else "medium",
                "analysis_confidence": min(1.0, len(components) * 0.2),
                "remediation_feasibility": "medium"  # Would be calculated from remediation options
            }
        }
    
    def generate_comprehensive_report(self, output_format: str = "markdown") -> str:
        """Generate a comprehensive vulnerability report"""
        if not self.reports:
            return "No vulnerability reports available. Run analyze_all_repositories() first."
        
        if output_format == "markdown":
            return self._generate_markdown_report()
        elif output_format == "json":
            return self._generate_json_report()
        else:
            return self._generate_text_report()
    
    def _generate_markdown_report(self) -> str:
        """Generate markdown format report"""
        report_lines = [
            "# üîí Vulnerability Analysis Report",
            f"*Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*",
            "",
            f"## üìä Executive Summary",
            f"- **Total Vulnerabilities Found:** {len(self.reports)}",
            f"- **Critical Issues:** {sum(1 for r in self.reports if r.vulnerability.severity == VulnerabilitySeverity.CRITICAL)}",
            f"- **High Severity:** {sum(1 for r in self.reports if r.vulnerability.severity == VulnerabilitySeverity.HIGH)}",
            f"- **Affected Repositories:** {len(set(repo for r in self.reports for repo in r.affected_repositories))}",
            "",
        ]
        
        # Add details for each vulnerability
        for i, report in enumerate(self.reports[:10], 1):  # Limit to top 10
            vuln = report.vulnerability
            recommended = report.recommended_action
            
            report_lines.extend([
                f"## üö® Vulnerability #{i}: {vuln.title}",
                f"- **Severity:** {vuln.severity.value.upper()}",
                f"- **CVSS Score:** {vuln.cvss_score or 'N/A'}",
                f"- **Source:** {vuln.source_db}",
                f"- **Affected Package:** {', '.join(vuln.affected_packages)}",
                "",
                f"### Description",
                vuln.description[:500] + ("..." if len(vuln.description) > 500 else ""),
                "",
                f"### Impact Analysis",
                f"- **Risk Score:** {report.risk_assessment.get('overall_risk', 'N/A')}",
                f"- **Affected Files:** {report.impact_analysis.get('impact_radius', 0)}",
                f"- **Urgency:** {report.impact_analysis.get('remediation_urgency', 'normal_cycle')}",
                "",
            ])
            
            if recommended:
                report_lines.extend([
                    f"### üîß Recommended Action",
                    f"- **Type:** {recommended.type.value}",
                    f"- **Description:** {recommended.description}",
                    f"- **Confidence:** {recommended.confidence_score:.1%}",
                    f"- **Compatibility Risk:** {recommended.compatibility_risk}",
                    "",
                    "**Steps:**",
                    *[f"1. {step}" for step in recommended.steps[:3]],
                    "",
                ])
        
        return "\n".join(report_lines)
    
    def _generate_json_report(self) -> str:
        """Generate JSON format report"""
        # Convert reports to JSON-serializable format
        json_reports = []
        for report in self.reports:
            json_report = {
                "vulnerability": {
                    "cve_id": report.vulnerability.cve_id,
                    "title": report.vulnerability.title,
                    "severity": report.vulnerability.severity.value,
                    "cvss_score": report.vulnerability.cvss_score,
                    "description": report.vulnerability.description,
                    "source_db": report.vulnerability.source_db
                },
                "impact_analysis": report.impact_analysis,
                "risk_assessment": report.risk_assessment,
                "affected_repositories": report.affected_repositories,
                "recommended_action": {
                    "type": report.recommended_action.type.value if report.recommended_action else None,
                    "description": report.recommended_action.description if report.recommended_action else None,
                    "confidence_score": report.recommended_action.confidence_score if report.recommended_action else None
                } if report.recommended_action else None,
                "generated_at": report.generated_at.isoformat()
            }
            json_reports.append(json_report)
        
        return json.dumps({
            "summary": {
                "total_vulnerabilities": len(self.reports),
                "critical_count": sum(1 for r in self.reports if r.vulnerability.severity == VulnerabilitySeverity.CRITICAL),
                "high_count": sum(1 for r in self.reports if r.vulnerability.severity == VulnerabilitySeverity.HIGH),
                "affected_repositories": len(set(repo for r in self.reports for repo in r.affected_repositories))
            },
            "vulnerabilities": json_reports
        }, indent=2)
    
    def _generate_text_report(self) -> str:
        """Generate plain text format report"""
        lines = [
            "VULNERABILITY ANALYSIS REPORT",
            "=" * 50,
            f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"Total Vulnerabilities: {len(self.reports)}",
            ""
        ]
        
        for i, report in enumerate(self.reports, 1):
            vuln = report.vulnerability
            lines.extend([
                f"VULNERABILITY #{i}:",
                f"  Title: {vuln.title}",
                f"  Severity: {vuln.severity.value}",
                f"  Package: {', '.join(vuln.affected_packages)}",
                f"  Risk Score: {report.risk_assessment.get('overall_risk', 'N/A')}",
                ""
            ])
        
        return "\n".join(lines)


async def main():
    """Demo function for vulnerability analysis"""
    print("üîí AI-Powered Vulnerability Analysis Agent - Demo")
    print("=" * 60)
    
    try:
        # Initialize dependency graph builder
        builder = DependencyGraphBuilder()
        
        # Initialize vulnerability analysis agent
        vuln_agent = VulnerabilityAnalysisAgent(builder)
        
        # Run comprehensive analysis
        print("üöÄ Starting vulnerability analysis of all repositories...")
        reports = await vuln_agent.analyze_all_repositories()
        
        if reports:
            print(f"üìã Analysis complete! Found {len(reports)} vulnerability issues")
            
            # Generate comprehensive report
            print("\nüìä Generating comprehensive report...")
            markdown_report = vuln_agent.generate_comprehensive_report("markdown")
            
            # Save report to file
            report_filename = f"vulnerability_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
            with open(report_filename, 'w') as f:
                f.write(markdown_report)
            
            print(f"‚úÖ Report saved to: {report_filename}")
            
            # Print summary
            critical_count = sum(1 for r in reports if r.vulnerability.severity == VulnerabilitySeverity.CRITICAL)
            high_count = sum(1 for r in reports if r.vulnerability.severity == VulnerabilitySeverity.HIGH)
            
            print(f"\nüö® VULNERABILITY SUMMARY:")
            print(f"   ‚Ä¢ Critical: {critical_count}")
            print(f"   ‚Ä¢ High: {high_count}")
            print(f"   ‚Ä¢ Total: {len(reports)}")
            
            if critical_count > 0:
                print(f"\n‚ö†Ô∏è  IMMEDIATE ACTION REQUIRED for {critical_count} critical vulnerabilities!")
        
        else:
            print("‚úÖ No vulnerabilities found in analyzed repositories")
    
    except Exception as e:
        print(f"‚ùå Vulnerability analysis failed: {e}")
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
